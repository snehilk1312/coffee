{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and install any necessary packages\n",
    "import spacy\n",
    "import warnings\n",
    "\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "# reading the data in doccano jsonl output format\n",
    "with open('data/admin.jsonl', 'r') as f:\n",
    "    lines = list(f)\n",
    "\n",
    "training_data: list = []\n",
    "\n",
    "for line in lines:\n",
    "    row = json.loads(line)\n",
    "    if row['label']:\n",
    "        training_data.append(  [ row[\"text\"], { \"entities\": row[\"label\"] } ] )\n",
    "\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"#1 fruit forward lots | 1 . 2 ell\\'sworth black honey orange , berry fruit characteristics , green grapes & lemon crisp acidity . suitable for all brew methods . origin chikmagalur , karnataka process hand picked cherries are pulped , sun dried on raised beds and then eventually washed before they are hulled . dry aroma mild florals wet aroma red ripe fruits based on sensory evaluation orange , berry fruit characteristics , green grapes & lemon crisp acidity . med body , clean mouthfeel & long prevailing aftertaste . varietal chandragiri roast profile light-med roast with variable drum speed and a lower charge temperature to achieve a 13% dtr . altitude 1130 masl minimum resting period filter 6 days | espresso 14 days a song that pairs well roaster thoughts : as black honey produces fruit forward flavors and consists of jammy characteristics . we roasted this coffee at 205 degrees to extract the dense properties , fruitier flavor notes and a heavier body . after cupping the coffee at 205 it was clear that this was a suitable roast profile for this coffee to unlock the full potential of this single farmer lot . this is certainly one of our favorite lots of this harvest season . roast profile : roast machine : probat development phase : 1m 25s charge temperature : 175 celsius first crack temperature : 193 celsius end bean temperature : 205 celsius about the estate : the time has come where we introduce you all to an estate and their humble producers we have been meaning to work with for long . producer ( smita shirley agera ) story : as a couple when we wanted to invest in a property , the only childhood desire of mine was to own a coffee estate , around the place i was born and grew up ( chikmagalur ) its almost 16 years now that we have owned this small piece of abode which is situated at 1130msl growing arabica & robusta\"',\n",
       " {'entities': [[42, 53, 'TASTING NOTES'],\n",
       "   [54, 60, 'TASTING NOTES'],\n",
       "   [63, 68, 'TASTING NOTES'],\n",
       "   [93, 105, 'TASTING NOTES'],\n",
       "   [108, 113, 'TASTING NOTES'],\n",
       "   [114, 119, 'ACIDITY'],\n",
       "   [169, 180, 'LOCATION'],\n",
       "   [183, 192, 'LOCATION'],\n",
       "   [449, 454, 'ACIDITY'],\n",
       "   [465, 473, 'BODY'],\n",
       "   [482, 491, 'BODY'],\n",
       "   [494, 509, 'AFTERTASTE'],\n",
       "   [532, 543, 'VARIETAL'],\n",
       "   [662, 671, 'ELEVATION'],\n",
       "   [1528, 1541, 'FARMER'],\n",
       "   [1716, 1727, 'LOCATION'],\n",
       "   [1820, 1827, 'ELEVATION'],\n",
       "   [1836, 1843, 'COFFEE TYPE'],\n",
       "   [1846, 1853, 'COFFEE TYPE']]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create spaCy DocBin objects from the annotated data\n",
    "def get_spacy_doc(file, data):\n",
    "  # Create a blank spaCy pipeline\n",
    "  nlp = spacy.blank('en')\n",
    "  db = DocBin()\n",
    "\n",
    "  # Iterate through the data\n",
    "  for text, annot in tqdm(data):\n",
    "    doc = nlp.make_doc(text)\n",
    "    annot = annot['entities']\n",
    "\n",
    "    ents = []\n",
    "    entity_indices = []\n",
    "\n",
    "    # Extract entities from the annotations\n",
    "    for start, end, label in annot:\n",
    "      skip_entity = False\n",
    "      for idx in range(start, end):\n",
    "        if idx in entity_indices:\n",
    "          skip_entity = True\n",
    "          break\n",
    "      if skip_entity:\n",
    "        continue\n",
    "\n",
    "      entity_indices = entity_indices + list(range(start, end))\n",
    "      try:\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode='strict')\n",
    "      except:\n",
    "        continue\n",
    "\n",
    "      if span is None:\n",
    "        # Log errors for annotations that couldn't be processed\n",
    "        err_data = str([start, end]) + \"    \" + str(text) + \"\\n\"\n",
    "        file.write(err_data)\n",
    "      else:\n",
    "        ents.append(span)\n",
    "\n",
    "    try:\n",
    "      doc.ents = ents\n",
    "      db.add(doc)\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "  return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snehil/.dev_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "100%|██████████| 71/71 [00:00<00:00, 904.85it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 664.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Split the annotated data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(training_data, test_size=0.1)\n",
    "\n",
    "# Display the number of items in the training and testing sets\n",
    "print(len(train), len(test))\n",
    "\n",
    "# Open a file to log errors during annotation processing\n",
    "file = open('train_file_try_1.txt','w')\n",
    "\n",
    "# Create spaCy DocBin objects for training and testing data\n",
    "db = get_spacy_doc(file, train)\n",
    "db.to_disk('train_doccano_try_1.spacy')\n",
    "\n",
    "db = get_spacy_doc(file, test)\n",
    "db.to_disk('test_doccano_try_1.spacy')\n",
    "\n",
    "# Close the error log file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "# configure spacy for custom NER model , using a base config file - https://spacy.io/usage/training#config\n",
    "\n",
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "\u001b[38;5;4mℹ Saving to output directory: output_try_1\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/thinc/shims/pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  -------------  --------  ------  ------  ------  ------\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/thinc/shims/pytorch.py:128: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "  0       0         228.29    586.15    0.00    0.00    0.00    0.00\n",
      " 22     200       43128.33  50125.96   38.33   50.00   31.08    0.38\n",
      " 44     400       29689.47   4839.70   59.74   57.50   62.16    0.60\n",
      " 66     600         343.78    526.74   52.63   51.28   54.05    0.53\n",
      " 88     800          98.41    151.27   52.94   58.06   48.65    0.53\n",
      "111    1000          46.75     83.76   52.98   51.95   54.05    0.53\n",
      "133    1200          49.78     72.83   52.78   54.29   51.35    0.53\n",
      "155    1400          50.32     51.08   49.30   51.47   47.30    0.49\n",
      "177    1600          53.71     71.41   49.25   55.00   44.59    0.49\n",
      "200    1800          38.54     45.24   48.92   52.31   45.95    0.49\n",
      "222    2000          43.64     50.47   54.93   57.35   52.70    0.55\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output_try_1/model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg  --output  output_try_1  --paths.train train_doccano_try_1.spacy  --paths.dev  test_doccano_try_1.spacy --gpu-id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and trying the model with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the spaCy library\n",
    "import spacy\n",
    "\n",
    "# Load the trained spaCy NER model from the specified path\n",
    "nlp = spacy.load('output_try_1/model-best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "This is the first Indian coffee we are adding to our travellers addition.  These are exquisite Indian  coffee beans, meticulously cultivated in the lush highlands of Chikmagalur. Kerehaklu is  a green haven tucked away in the Western Ghats. The plantation is spread across 250 acres and is a 15-minute drive from the closest village of Aldur, making it a secluded getaway amid fascinating flora, fauna and fungi. This experimental batch is proccesed with Pichia yeast anoxic fermentation. \n",
    "\n",
    "Tasting Notes:\n",
    "\n",
    "Kerehaklu coffee is a true sensory delight, offering a symphony of distinct tasting notes that will enchant your palate. At first sip, you'll encounter the gentle and toasty sweetness of caramel, followed by the refreshing strawbery notes. The flavor journey continues with the delightful vanilla. \n",
    "\n",
    "As the coffee dances across your taste buds, subtle hints of creamy vanilla emerge, adding a velvety richness to the overall profile.\n",
    "\n",
    "The finishing note is a delicate and aromatic rose essence that leaves a floral aftertaste. \n",
    "\n",
    " These remarkable coffee beans are a testament to the dedication and expertise of Pranoy & Ajoy  from the  Kerehaklu plantation family, who nurture them at each stage. The result is a truly unique and memorable coffee that invites you to savor each sip, allowing you to explore a world of flavors within the confines of your cup. Kerehaklu Pichia Yeast Anoxic fermented Coffee is the perfect companion for those seeking a refined and adventurous coffee experience.\n",
    "\n",
    "Cultivated in the pristine regions of India and nurtured with care, these beans offer a unique flavor profile that reflects the terroir of its origin. With each sip, you'll taste the earthy undertones, hints of spice, and a velvety smoothness that defines Indian coffee.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chikmagalur   ->>>>   LOCATION\n",
      "Kerehaklu is   ->>>>   NAME\n",
      "Aldur,   ->>>>   LOCATION\n",
      "caramel   ->>>>   TASTING NOTES\n",
      "vanilla   ->>>>   TASTING NOTES\n",
      "rose   ->>>>   TASTING NOTES\n",
      "Pranoy &   ->>>>   FARMER\n",
      "Ajoy     ->>>>   FARMER\n",
      "spice   ->>>>   TASTING NOTES\n"
     ]
    }
   ],
   "source": [
    "# Process the extracted text using the loaded spaCy NER model\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate through the named entities (entities) recognized by the model\n",
    "for ent in doc.ents:\n",
    "  # Print the recognized text and its corresponding label\n",
    "  print(ent.text, \"  ->>>>  \", ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =\"\"\"\n",
    "Coffee Tasting Notes (Not flavours): Clean, Citrus, Pleasant, Short Aftertaste\n",
    "\n",
    "Product is 100% Arabica Coffee direct from our farm. This variant is part of our mission to introduce consumers to pure Coffee.\n",
    "\n",
    "(Cinnamon Roast) Light roasted coffee is the reward for hardwork by speciality Coffee roasters all around the world. This variant of Coffee which cannot be produced by low quality coffee beans. Light Roasted Coffee bean retains its origin flavours. Unique characteristics of Coffee is retained (which will be lost as roast level increases). Only A graded Arabica Coffee beans is used to make this roast.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean   ->>>>   TASTING NOTES\n",
      "Citrus   ->>>>   TASTING NOTES\n",
      "Pleasant   ->>>>   TASTING NOTES\n",
      "Short   ->>>>   AFTERTASTE\n",
      "Arabica   ->>>>   COFFEE TYPE\n",
      "Light   ->>>>   ROAST LEVEL\n"
     ]
    }
   ],
   "source": [
    "# Process the extracted text using the loaded spaCy NER model\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate through the named entities (entities) recognized by the model\n",
    "for ent in doc.ents:\n",
    "  # Print the recognized text and its corresponding label\n",
    "  print(ent.text, \"  ->>>>  \", ent.label_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
