{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and install any necessary packages\n",
    "import spacy\n",
    "import warnings\n",
    "\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n"
     ]
    }
   ],
   "source": [
    "# reading the data in doccano jsonl output format\n",
    "with open('data/admin.jsonl', 'r') as f:\n",
    "    lines = list(f)\n",
    "\n",
    "training_data: list = []\n",
    "\n",
    "for line in lines:\n",
    "    row = json.loads(line)\n",
    "    if row['label']:\n",
    "        training_data.append(  [ row[\"text\"], { \"entities\": row[\"label\"] } ] )\n",
    "\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"#1 fruit forward lots | 1 . 2 ell\\'sworth black honey orange , berry fruit characteristics , green grapes & lemon crisp acidity . suitable for all brew methods . origin chikmagalur , karnataka process hand picked cherries are pulped , sun dried on raised beds and then eventually washed before they are hulled . dry aroma mild florals wet aroma red ripe fruits based on sensory evaluation orange , berry fruit characteristics , green grapes & lemon crisp acidity . med body , clean mouthfeel & long prevailing aftertaste . varietal chandragiri roast profile light-med roast with variable drum speed and a lower charge temperature to achieve a 13% dtr . altitude 1130 masl minimum resting period filter 6 days | espresso 14 days a song that pairs well roaster thoughts : as black honey produces fruit forward flavors and consists of jammy characteristics . we roasted this coffee at 205 degrees to extract the dense properties , fruitier flavor notes and a heavier body . after cupping the coffee at 205 it was clear that this was a suitable roast profile for this coffee to unlock the full potential of this single farmer lot . this is certainly one of our favorite lots of this harvest season . roast profile : roast machine : probat development phase : 1m 25s charge temperature : 175 celsius first crack temperature : 193 celsius end bean temperature : 205 celsius about the estate : the time has come where we introduce you all to an estate and their humble producers we have been meaning to work with for long . producer ( smita shirley agera ) story : as a couple when we wanted to invest in a property , the only childhood desire of mine was to own a coffee estate , around the place i was born and grew up ( chikmagalur ) its almost 16 years now that we have owned this small piece of abode which is situated at 1130msl growing arabica & robusta\"',\n",
       " {'entities': [[42, 53, 'TASTING NOTES'],\n",
       "   [54, 60, 'TASTING NOTES'],\n",
       "   [63, 68, 'TASTING NOTES'],\n",
       "   [93, 105, 'TASTING NOTES'],\n",
       "   [108, 113, 'TASTING NOTES'],\n",
       "   [114, 119, 'ACIDITY'],\n",
       "   [169, 180, 'LOCATION'],\n",
       "   [183, 192, 'LOCATION'],\n",
       "   [449, 454, 'ACIDITY'],\n",
       "   [465, 473, 'BODY'],\n",
       "   [482, 491, 'BODY'],\n",
       "   [494, 509, 'AFTERTASTE'],\n",
       "   [532, 543, 'VARIETAL'],\n",
       "   [662, 671, 'ELEVATION'],\n",
       "   [1528, 1541, 'FARMER'],\n",
       "   [1716, 1727, 'LOCATION'],\n",
       "   [1820, 1827, 'ELEVATION'],\n",
       "   [1836, 1843, 'COFFEE TYPE'],\n",
       "   [1846, 1853, 'COFFEE TYPE']]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create spaCy DocBin objects from the annotated data\n",
    "def get_spacy_doc(file, data):\n",
    "  # Create a blank spaCy pipeline\n",
    "  nlp = spacy.blank('en')\n",
    "  db = DocBin()\n",
    "\n",
    "  # Iterate through the data\n",
    "  for text, annot in tqdm(data):\n",
    "    doc = nlp.make_doc(text)\n",
    "    annot = annot['entities']\n",
    "\n",
    "    ents = []\n",
    "    entity_indices = []\n",
    "\n",
    "    # Extract entities from the annotations\n",
    "    for start, end, label in annot:\n",
    "      skip_entity = False\n",
    "      for idx in range(start, end):\n",
    "        if idx in entity_indices:\n",
    "          skip_entity = True\n",
    "          break\n",
    "      if skip_entity:\n",
    "        continue\n",
    "\n",
    "      entity_indices = entity_indices + list(range(start, end))\n",
    "      try:\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode='strict')\n",
    "      except:\n",
    "        continue\n",
    "\n",
    "      if span is None:\n",
    "        # Log errors for annotations that couldn't be processed\n",
    "        err_data = str([start, end]) + \"    \" + str(text) + \"\\n\"\n",
    "        file.write(err_data)\n",
    "      else:\n",
    "        ents.append(span)\n",
    "\n",
    "    try:\n",
    "      doc.ents = ents\n",
    "      db.add(doc)\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "  return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snehil/.dev_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "100%|██████████| 134/134 [00:00<00:00, 885.41it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 680.57it/s]\n"
     ]
    }
   ],
   "source": [
    "# Split the annotated data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(training_data, test_size=0.1)\n",
    "\n",
    "# Display the number of items in the training and testing sets\n",
    "print(len(train), len(test))\n",
    "\n",
    "# Open a file to log errors during annotation processing\n",
    "file = open('train_file_try_2.txt','w')\n",
    "\n",
    "# Create spaCy DocBin objects for training and testing data\n",
    "db = get_spacy_doc(file, train)\n",
    "db.to_disk('train_doccano_try_2.spacy')\n",
    "\n",
    "db = get_spacy_doc(file, test)\n",
    "db.to_disk('test_doccano_try_2.spacy')\n",
    "\n",
    "# Close the error log file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
      "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "# configure spacy for custom NER model , using a base config file - https://spacy.io/usage/training#config\n",
    "\n",
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "\u001b[38;5;2m✔ Created output directory: output_try_2\u001b[0m\n",
      "\u001b[38;5;4mℹ Saving to output directory: output_try_2\u001b[0m\n",
      "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/thinc/shims/pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
      "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  -------------  --------  ------  ------  ------  ------\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/thinc/shims/pytorch.py:128: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n",
      "  0       0        1475.28   1145.36    0.00    0.00    0.00    0.00\n",
      " 11     200     5306694.53  165235.56    0.00    0.00    0.00    0.00\n",
      " 23     400       83825.90  24757.39   43.18   71.70   30.89    0.43\n",
      " 35     600       11028.42   8020.28   62.62   73.63   54.47    0.63\n",
      " 47     800        3919.88   2702.52   57.27   62.50   52.85    0.57\n",
      " 58    1000         453.57    603.52   59.13   63.55   55.28    0.59\n",
      " 70    1200         238.13    357.99   60.73   60.48   60.98    0.61\n",
      " 82    1400         121.40    168.82   58.52   63.21   54.47    0.59\n",
      " 94    1600         143.03    172.71   58.58   60.34   56.91    0.59\n",
      "105    1800         134.11    144.13   58.01   62.04   54.47    0.58\n",
      "117    2000          66.73     88.40   59.75   61.02   58.54    0.60\n",
      "129    2200         150.58    135.40   57.26   60.36   54.47    0.57\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output_try_2/model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg  --output  output_try_2  --paths.train train_doccano_try_2.spacy  --paths.dev  test_doccano_try_2.spacy --gpu-id 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and trying the model with new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the spaCy library\n",
    "import spacy\n",
    "\n",
    "# Load the trained spaCy NER model from the specified path\n",
    "nlp = spacy.load('output_try_2/model-best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Jasmine kissed cranberry - 100 % arabica that is sourced from Chikmagalur, grown at an altitude of approximately 4,100ft to 4,500ft. It gets its unique name through a process which include a strain of yeast used to create a carbon dioxide-rich environment during fermentation in stainless-steel fermenters. A remarkable level of complexity in the beans is created by this process, laying the groundwork for a wonderful cup of coffee. Steady drying on raised beds is the next important step, which lets the flavors gradually develop and intensify. After another 30 days of continuous stirring, the coffee undergo additional drying developing scent of jasmine, complex notes of raspberries, cranberries, and sparkling malic acidity with a lingering floral aftertaste \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jasmine kissed cranberry -   ->>>>   NAME\n",
      "arabica   ->>>>   COFFEE TYPE\n",
      "chikmagalur   ->>>>   LOCATION\n",
      "jasmine   ->>>>   TASTING NOTES\n",
      "raspberries   ->>>>   TASTING NOTES\n",
      "cranberries   ->>>>   TASTING NOTES\n",
      "malic   ->>>>   ACIDITY\n"
     ]
    }
   ],
   "source": [
    "# Process the extracted text using the loaded spaCy NER model\n",
    "doc = nlp(text.lower())\n",
    "\n",
    "# Iterate through the named entities (entities) recognized by the model\n",
    "for ent in doc.ents:\n",
    "  # Print the recognized text and its corresponding label\n",
    "  print(ent.text, \"  ->>>>  \", ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "text =\"\"\"\n",
    "Single origin Indian Coffee From Moganad Estate, Tamil Nadu which is a 100% Arabiaca coffee with \n",
    "an exquisite blend of balanced sweetness and brightness. A Medium Dark Roast coffee with \n",
    "flavor notes of Cocoa, Caramel and Nut which can also be enjoyed in a French press, moka pot, aeropress & espresso .\n",
    " It is washed processed, grown at an altitude of around 4430 ft\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moganad   ->>>>   ESTATE\n",
      "tamil nadu   ->>>>   LOCATION\n",
      "medium dark   ->>>>   ROAST LEVEL\n",
      "cocoa   ->>>>   TASTING NOTES\n",
      "caramel   ->>>>   TASTING NOTES\n",
      "nut   ->>>>   TASTING NOTES\n",
      "4430 ft   ->>>>   ELEVATION\n"
     ]
    }
   ],
   "source": [
    "# Process the extracted text using the loaded spaCy NER model\n",
    "doc = nlp(text.lower())\n",
    "\n",
    "# Iterate through the named entities (entities) recognized by the model\n",
    "for ent in doc.ents:\n",
    "  # Print the recognized text and its corresponding label\n",
    "  print(ent.text, \"  ->>>>  \", ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
