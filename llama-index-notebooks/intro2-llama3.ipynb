{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook is just to show how rag can be useful, we will just feed data as text and will observe the answers to see that when context is provided answers are much relevant . No optimization have been done , default data load and using llama3 as model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\snehi\\Desktop\\Learning\\.dev_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.readers.database import DatabaseReader\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the environment variables\n",
    "load_dotenv('..\\.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating embeddings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.core.embeddings import resolve_embed_model\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "# ollama\n",
    "Settings.llm = Ollama(model=\"llama3\", request_timeout=60.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reload from local persist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reloading index\n",
    "\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "# rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"embed_dir_dataengineering_comments/\")\n",
    "\n",
    "# load index\n",
    "index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without context llm\n",
    "\n",
    "llm_without_context = Ollama(model=\"llama3\", request_timeout=60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What a fascinating topic!\n",
      "\n",
      "Generative AI has been revolutionizing the field of Data Engineering, transforming the way we collect, process, and analyze data. Here are some ways generative AI is impacting my work as a Data Engineer:\n",
      "\n",
      "1. **Data Generation**: Generative models like GANs (Generative Adversarial Networks) and VAEs (Variational Autoencoders) can generate synthetic data that mimics the patterns and distributions of real-world datasets. This synthetic data can be used to augment existing datasets, reducing the need for additional data collection and improving model performance.\n",
      "2. **Data Imputation**: Generative AI can also help fill missing values in datasets by predicting or imputing them based on the relationships between variables. This reduces the risk of biased models and improves overall data quality.\n",
      "3. **Data Transformation**: Generative models can transform high-dimensional data into lower-dimensional representations, making it easier to visualize and analyze complex datasets.\n",
      "4. **Anomaly Detection**: By learning patterns in normal data, generative AI can detect anomalies and outliers more effectively than traditional methods. This is particularly useful for detecting fraud or unusual behavior in financial transactions.\n",
      "5. **Data Clustering**: Generative models can group similar data points together based on their patterns and relationships, making it easier to identify clusters and trends in large datasets.\n",
      "\n",
      "The impact of generative AI on my work as a Data Engineer has been significant:\n",
      "\n",
      "1. **Increased Efficiency**: With generative AI, I can focus more on high-level decision-making and less on tedious data preparation tasks.\n",
      "2. **Improved Accuracy**: Generative models have allowed me to develop more accurate predictive models by incorporating synthetic or imputed data into the training process.\n",
      "3. **Enhanced Insights**: The transformed and imputed data enables me to uncover new insights and patterns that might have been hidden in the original data.\n",
      "4. **Reduced Bias**: By generating synthetic data, I can reduce the risk of biased models and ensure a more representative sample for my analysis.\n",
      "\n",
      "However, I also face some challenges:\n",
      "\n",
      "1. **Interpretability**: Generative AI models can be difficult to interpret, making it challenging to understand why certain predictions or patterns are emerging.\n",
      "2. **Training Time**: Training generative AI models requires significant computational resources and time, which can be a bottleneck in my workflow.\n",
      "3. **Evaluation Metrics**: Developing effective evaluation metrics for generative AI models is crucial but also presents challenges.\n",
      "\n",
      "Overall, the integration of generative AI into Data Engineering has opened up new possibilities for data analysis, modeling, and decision-making. While it requires additional expertise and resources, the benefits are undeniable, and I'm excited to see where this technology takes us in the future!\n"
     ]
    }
   ],
   "source": [
    "resp = llm_without_context.complete(\"role of generative ai in data engineering and how it is affecting you?\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to current capabilities, Generative AI is still in the \"augment\" phase for data engineering. It doesn't pose a risk to replacing us, although this could change rapidly given the rapid advancements being made. In our company's case, we're finding success using OpenAI's API endpoints for tasks such as sentiment analysis and basic fraud detection. This has led us to conclude that most generative AI core tasks can be handled through these APIs, at least in our small-to-medium-sized company setting.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"role of generative ai in data engineering and how it is affecting you?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a data engineer with few years of experience, here are some tips to help you progress in your career:\n",
      "\n",
      "**1. Specialize**: Focus on a specific area of data engineering, such as:\n",
      "\t* Cloud computing (e.g., AWS, Azure, GCP)\n",
      "\t* Big Data platforms (e.g., Hadoop, Spark, Hive)\n",
      "\t* Machine Learning and AI\n",
      "\t* Data Governance and Compliance\n",
      "\t* Data Architecture and Design\n",
      "\n",
      "**2. Develop complementary skills**: Acquire skills that complement your data engineering expertise, such as:\n",
      "\t* Programming languages (e.g., Python, Java, Scala)\n",
      "\t* Data science and analytics tools (e.g., Tableau, Power BI, R)\n",
      "\t* Database administration (e.g., MySQL, PostgreSQL)\n",
      "\t* Cloud security and compliance\n",
      "\n",
      "**3. Stay up-to-date with industry trends**: Continuously learn about new technologies, frameworks, and methodologies in the data engineering space. This will help you stay relevant and competitive.\n",
      "\n",
      "**4. Pursue certifications or higher education**: Consider obtaining certifications like Certified Data Engineer (CDE) or pursuing a Master's degree in Data Science or related fields to enhance your credibility and career prospects.\n",
      "\n",
      "**5. Network and build relationships**: Attend industry conferences, join online communities (e.g., Kaggle, Reddit), and connect with professionals in the field. This will help you stay informed about job opportunities and best practices.\n",
      "\n",
      "**6. Create a personal project or contribute to open-source projects**: Showcase your skills by developing a personal project or contributing to open-source data engineering projects on platforms like GitHub.\n",
      "\n",
      "**7. Set career goals**: Establish specific, measurable, achievable, relevant, and time-bound (SMART) goals for yourself, such as:\n",
      "\t* Obtaining a certain certification\n",
      "\t* Completing a specific training program\n",
      "\t* Taking on more responsibilities at your current job\n",
      "\t* Moving to a new role or company\n",
      "\n",
      "**8. Consider moving into leadership roles**: As you gain experience, consider taking on leadership roles, such as data engineering manager or architect, which can provide opportunities for career growth and increased responsibility.\n",
      "\n",
      "**9. Develop soft skills**: Focus on building strong communication, collaboration, and problem-solving skills, which are essential for success in any data engineering role.\n",
      "\n",
      "**10. Stay flexible and open-minded**: Be willing to adapt to new technologies, methodologies, and industry shifts, and remain open to new opportunities and challenges.\n",
      "\n",
      "By following these tips, you'll be well-positioned to progress in your career as a data engineer with few years of experience.\n"
     ]
    }
   ],
   "source": [
    "resp = llm_without_context.complete(\"how you should progress in career when you have few years of experience in data engineering, answer from the context provided?\")\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Even a year of an adjacent type role is better than nothing, and it's easier to transition within the company to a data engineer if you want to expand your skills on the job.\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"how you should progress in career when you have few years of experience in data engineering, answer from the context provided?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
