{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snehil/.dev_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from gliner_spacy.pipeline import GlinerSpacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snehil/.dev_env/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/transformers/modeling_utils.py:519: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=map_location)\n",
      "/home/snehil/.dev_env/lib/python3.12/site-packages/gliner/model.py:405: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_file, map_location=torch.device(map_location))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gliner_spacy.pipeline.GlinerSpacy at 0x7fd1cb7cdb80>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.add_pipe(\"gliner_spacy\",config={'labels':['elevation','estate','processing_method','roast_level','coffee_varietal','fermentation_time',\n",
    "'tasting_notes','location','aroma','body','acidity','roaster_name','farmer','texture','coffee_type','brewing_method'\n",
    "]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "Anuswaram in Carnatic parlance means a note between notes and denotes complex melodic movements that rāga-s tend to employ.\n",
    "\n",
    "We sometimes receive small lots of coffee that really captivate us with their complexity or innovative processing. We feel that Anuswaram is a fitting name for featuring these intriguing offerings. The 4th in this series is a very special washed coffee from the lofty hills of Valparai.\n",
    "\n",
    "Located in the Thalanar region of the Valparai plateau, Greenland estate is spread over 200 acres and at an altitude of 1500- 1737m ASL, is one of the highest farms that we have sourced from. The owner Mr. Govind, is very eager to make inroads into the speciality coffee segment and nothing showcases what the farm has to offer like this washed lot.\n",
    "\n",
    " To prepare this, cherries of the SLN 09 varietal were picked picked ripe, pulped (i.e. skin was removed) and fermented for 18 hours. The coffee beans were  then washed  and slow dried for a fortnight on raised beds.\n",
    "\n",
    " The low temperatures(because  of the high altitude) and the care taken during processing have made this coffee an absolute delight in the cup! There's a very prominent jaggery like sweetness, a partly peachy ,  partly orange-like acidity and a whole bunch of florals, some of.which we could triangulate and some which we couldn't. All this complexity is very reminiscent of African coffees and quite uncommon in Indian offerings. \n",
    "\n",
    " We thank Mr. Viggnesh for having helped source this beautiful coffee for us and hope to work with Greenland estate more closely in future!\n",
    "\n",
    "Anuswaram #4 is a delight across all manual brews but shines best in a v60.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rāga-s coffee_varietal\n",
      "coffee coffee_type\n",
      "anuswaram roaster_name\n",
      "valparai location\n",
      "thalanar region location\n",
      "valparai location\n",
      "greenland estate estate\n",
      "200 acres location\n",
      "altitude elevation\n",
      "farms location\n",
      "mr. govind farmer\n",
      "farm location\n",
      "sln 09 coffee_varietal\n",
      "pulped processing_method\n",
      "skin texture\n",
      "18 hours fermentation_time\n",
      "coffee beans coffee_type\n",
      "raised beds location\n",
      "high altitude elevation\n",
      "processing processing_method\n",
      "coffee coffee_type\n",
      "jaggery acidity\n",
      "peachy acidity\n",
      "orange-like acidity\n",
      "florals aroma\n",
      "african coffees coffee_type\n",
      "mr. viggnesh roaster_name\n",
      "greenland estate\n",
      "anuswaram #4 coffee_varietal\n",
      "manual brews brewing_method\n",
      "v60 roast_level\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text.lower())\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".dev_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
